[{"id":0,"href":"/blog/posts/getting-started-tiling-wm-part-1-i3/","title":"Getting Started with Tiling WM [Part 1] - I3","section":"Posts","content":"Disclaimer\nI love customizing desktop. I make changes in my desktop everyday, make it look eye candy. My colleagues ask me how to make their desktop look like mine. But there are many steps and things to learn and follow, I know because I\u0026rsquo;ve gone throught it. Therefore I decide to write this getting-started guide to give people a shortest path to Fancy world.\n 1. Overview Window Manager #  First of all, you have to know the basic concepts.\n1.1. Desktop Environment vs. Window Manager #  We\u0026rsquo;ll begin by showing how the Linux graphical desktop is layered. There are basically 3 layers that can be included in the Linux desktop:\n X Window: All GUIs require an X Window System layer, which draws graphic elements on the display. Without the X server, neither a WM nor a DE could create images on a Linux display. X also creates a framework for moving windows and performing tasks using a mouse and keyboard. Window manager:  A WM controls the placement and appearance of screen elements. Popular WMs: i3, awesome, dwm\u0026hellip; Requires configuration to get what you want. Tends to be flexible and highly customizable. Customizes most aspects of a Linux experience. For Nerd: not user-friendly out of the box, need to edit configuration files\u0026hellip;   Desktop environment:  A DE requires both X and a WM. It also adds the deeper and seemless integration with applications, panels, system menus, status applets, drag-and-drop functionality,\u0026hellip; The most popular DEs: KDE Plasma, GNOME, Pantheon, Cinnamon,\u0026hellip; Sounds familiar, right? Excellent default configurations. May not be particularly customizable. Gret if you don\u0026rsquo;t want to customize everything.     mermaid.initialize({ \"flowchart\": { \"useMaxWidth\":true }, \"theme\": \"default\" } ) graph TD; A[Desktop Environment] -- B[Window Manager]; B -- C[X Windows]; 1.2. Types of Window Manager #   Stack window manager:  A stack window manager renders the window one-by-one onto the screen at specific co-orinates. If one window\u0026rsquo;s area overlaps another, then the window \u0026ldquo;on top\u0026rdquo; overwites part of the other\u0026rsquo;s visible appearance. This results in the appearance familiar to many users in which windows act a little like pieces of paper on a desktop, which can be moved around and allowed to overlap. Openbox, Fluxbox, Enlightenment\u0026hellip;   Tiling window manager:  A window manager with an organization of the screen into mutually non-overlapping frames (hence the name tiling), as opposed to the traditional approach of coordinate-based stacking of objects (windows) that tries to emulate the desk paradigm. Awesome,i3 (here we go), dwm, bspwm\u0026hellip;   Compositing window manager:  A compositing window manager may appear to the user similar to a stacking window manager. However, the individual windows are first renders in individual buffers, and then theirs images are composited onto the screen buffer; this two-step process means that visual effects (such as shadows, translucency) can be applied. Mutter (GNOME), Xfwm (XFCE), Compiz (Unity), KWin (KDE)    2. Overview I3 #   i3wm is a tiling window manager designed for X11. It supports tiling, stacking, and tabbing layouts, which it handles dynamically. Configuration is achieved via plain text file. Keyboard navigation: Hall full control with keyboard navigation. Minimalistic: no window decorations or nonsense icons floating around. But you can fully customize it. Window management: is left to the user. Windows are held inside containers, which can be split veritically or horizontally. They can also optionally be resized. There are also options for stacking the windows, as well as tabbing them. Floating pop-up windows. Want more, check this.  3. Minimal I3 setup #  3.1. Operating System #   Ubuntu 20.04 (Desktop/Server), download the installer and install Ubuntu by walking through installer. If you choose Ubuntu Server, you\u0026rsquo;ll need a display server so let\u0026rsquo;s install X Window System (Xorg).  1sudo apt install xinit 2# The configuration files are stored in /etc/X11/xinit 3# You can override it by creating and modifying ~/.xinitrc 3.2. Install I3 #   You can install i3 from Ubuntu repository. It includes the window manager, a screen locker and two programs which write a status line to i3bar through stdout.  Note that, i3-wm conflicts with i3-gaps (a fork of i3 with gaps and other features).  1sudo apt install i3  Or build from source, I have a personal fork - Rounded i3-gaps.  1# Dependencies 2sudo apt install git libxcb1-dev libxcb-keysyms1-dev libpango1.0-dev \\ 3 libxcb-util0-dev libxcb-icccm4-dev libyajl-dev \\ 4 libstartup-notification0-dev libxcb-randr0-dev \\ 5 libev-dev libxcb-cursor-dev libxcb-xinerama0-dev \\ 6 libxcb-xkb-dev libxkbcommon-dev libxkbcommon-x11-dev \\ 7 autoconf libxcb-xrm0 libxcb-xrm-dev automake i3status \\ 8 ninja-build meson libxcb-shape0-dev build-essential -y 9git clone https://github.com/ntk148v/i3.git 10cd i3/ 11# Compile 12mkdir -p build \u0026amp;\u0026amp; cd build 13meson .. 14ninja 15sudo ninja install   Reboot. After reboot, choose i3 as your WM/DE.\n  A prompt will be shown to create a config file, just hit \u0026lt;Enter\u0026gt;.\n        \u0026lt;mod\u0026gt; key is Window now. Hit \u0026lt;mod\u0026gt;+Enter to start terminal emulator.\n  We have i3 first setup here with the default configuration. As mentioned before, configuration is achieved via plain text file.\n      4. Usage #  This post doesn\u0026rsquo;t aim to cover everything about i3, see the official documentation for more information.\n4.1. Keybindings #   In i3, commands are invoked with a modifier key, referred to as $mod. This is Alt (Mod1) by default, with Super (Mod4) being a popular alternative. Super is the key usually represented on a keyboard as a Windows icon, or on an Apple keyboard as a Command key. See i3 reference card and Using i3 for defaults.      4.2. Workspace, Container and Window #  graph TD; i3--Workspace1; i3--Workspace2; Workspace1--Container1; Workspace1--Container2; Container1--Window1; Container2--Window2; Workspace2--Container3; Container3--Window3; Container3--Window4; style i3 fill:#33ddaa; style Workspace1 fill:#ea9999; style Workspace2 fill:#ea9999; style Container1 fill:#6fa8dc; style Container2 fill:#6fa8dc; style Container3 fill:#6fa8dc;  In i3, workspace is simply the equivalent of a virtual desktop. You can have as many workspaces as you want. i3 manages windows in a tree structure, with containers as building blocks. A container contains one or multiple windows. Its windows will be positioned depending on the container\u0026rsquo;s layout. There are 3 different layouts possible:  Split: Each window share the container space and are split horizontally (splith) or vertically (splitv). This is the default layout. Stacked - The focused window is visible and the other ones are stacked behind. You can change the window’s focus via keystrokes easily. You have access to the list of windows open too, at the top of the container itself. Tabbed - This layout is similar as the stacked layout, except that the windows’ list is vertically split, and not horizontally.   A window, where an application is running, can be created in a container. It will automatically position itself and be in focus, depending on the container’s layout. You can move them around or even change the layout of the container using keystrokes. There are two different sorts of windows: fixed windows (by default) and floating windows.  4.3. Application launcher #   i3 uses dmenu as an application launcher, which is bound by default to $mod+d. rofi is a popular dmenu replacement and more that can list dekstop entries.  5. Configuration #   You can use my minimal configuration. It requires some extra packages.  1sudo apt install hsetroot rofi compton -y Minimal I3 configuration Cheat sheat shortcut #     Shortcut Description     $mod + Enter Open a terminal   $mod + d Open application launcher   $mod + c Kill focused window   $mod + right/left/up/down Change focus   $mod + Shift + right/left/up/down Move focused window in direction   $mod + 1/2/3\u0026hellip; Switch workspace   $mod + Shift + 1/2/3\u0026hellip; Move focused window to the specified workspace   $mod + space Change between focus and floating mode   $mod + Shift + r Restart i3   $mod + Shift + c Reload config i3   $mod + q Quit i3    Minimal configuration file #  # i3 config file # Please see https://i3wm.org/docs/userguide.html for a complete reference! # Set modifier set $mod Mod4 set $alt Mod1 default_orientation auto # Font for window titles. font pango:DejaVu Sans Mono 0 # Use Mouse+$mod to drag floating windows to their wanted position floating_modifier $mod # Here is the trick to disable titlebar completely for_window [class=\u0026quot;^.*\u0026quot;] border pixel 0 # Autostart exec --no-startup-id hsetroot -solid \u0026quot;#F1CCBB\u0026quot; exec --no-startup-id xsettingsd \u0026amp; exec --no-startup-id compton -b exec --no-startup-id xss-lock --transfer-sleep-lock -- i3lock --nofork exec --no-startup-id nm-applet # Keybindings # start a terminal bindsym $mod+Return exec i3-sensible-terminal # kill focused window bindsym $mod+c kill bindsym $alt+F4 kill # start rofi bindsym $mod+Shift+d exec i3-dmenu-desktop --dmenu=\u0026quot;dmenu -i -fn 'DejaVu Sans:size=8'\u0026quot; bindsym $mod+d exec rofi -lines 12 -padding 18 -width 60 -location 0 -show drun -sidebar-mode -columns 3 -font 'DejaVu Sans 8' # Use pactl to adjust volume in PulseAudio. set $refresh_i3status killall -SIGUSR1 i3status bindsym XF86AudioRaiseVolume exec --no-startup-id pactl set-sink-volume @DEFAULT_SINK@ +10% \u0026amp;\u0026amp; $refresh_i3status bindsym XF86AudioLowerVolume exec --no-startup-id pactl set-sink-volume @DEFAULT_SINK@ -10% \u0026amp;\u0026amp; $refresh_i3status bindsym XF86AudioMute exec --no-startup-id pactl set-sink-mute @DEFAULT_SINK@ toggle \u0026amp;\u0026amp; $refresh_i3status bindsym XF86AudioMicMute exec --no-startup-id pactl set-source-mute @DEFAULT_SOURCE@ toggle \u0026amp;\u0026amp; $refresh_i3status # change focus bindsym $mod+Left focus left bindsym $mod+Down focus down bindsym $mod+Up focus up bindsym $mod+Right focus right # alternatively, you can use the cursor keys: bindsym $mod+Shift+Left move left bindsym $mod+Shift+Down move down bindsym $mod+Shift+Up move up bindsym $mod+Shift+Right move right # split in horizontal orientation bindsym $mod+h split h # split in vertical orientation bindsym $mod+v split v # enter fullscreen mode for the focused container bindsym $mod+f fullscreen toggle # change container layout (stacked, tabbed, toggle split) bindsym $mod+s layout stacking bindsym $mod+w layout tabbed bindsym $mod+e layout toggle split # toggle tiling / floating bindsym $mod+Shift+space floating toggle # change focus between tiling / floating windows bindsym $mod+space focus mode_toggle # focus the parent container bindsym $mod+a focus parent # Define names for default workspaces for which we configure key bindings later on. # We use variables to avoid repeating the names in multiple places. set $ws1 \u0026quot;1\u0026quot; set $ws2 \u0026quot;2\u0026quot; set $ws3 \u0026quot;3\u0026quot; set $ws4 \u0026quot;4\u0026quot; set $ws5 \u0026quot;5\u0026quot; set $ws6 \u0026quot;6\u0026quot; set $ws7 \u0026quot;7\u0026quot; set $ws8 \u0026quot;8\u0026quot; set $ws9 \u0026quot;9\u0026quot; set $ws10 \u0026quot;10\u0026quot; # switch to workspace bindsym $mod+1 workspace number $ws1 bindsym $mod+2 workspace number $ws2 bindsym $mod+3 workspace number $ws3 bindsym $mod+4 workspace number $ws4 bindsym $mod+5 workspace number $ws5 bindsym $mod+6 workspace number $ws6 bindsym $mod+7 workspace number $ws7 bindsym $mod+8 workspace number $ws8 bindsym $mod+9 workspace number $ws9 bindsym $mod+0 workspace number $ws10 # move focused container to workspace bindsym $mod+Shift+1 move container to workspace number $ws1 bindsym $mod+Shift+2 move container to workspace number $ws2 bindsym $mod+Shift+3 move container to workspace number $ws3 bindsym $mod+Shift+4 move container to workspace number $ws4 bindsym $mod+Shift+5 move container to workspace number $ws5 bindsym $mod+Shift+6 move container to workspace number $ws6 bindsym $mod+Shift+7 move container to workspace number $ws7 bindsym $mod+Shift+8 move container to workspace number $ws8 bindsym $mod+Shift+9 move container to workspace number $ws9 bindsym $mod+Shift+0 move container to workspace number $ws10 # reload the configuration file bindsym $mod+Shift+c reload # restart i3 inplace (preserves your layout/session, can be used to upgrade i3) bindsym $mod+Shift+r restart # exit i3 (logs you out of your X session) bindsym $mod+Shift+e exec \u0026quot;i3-nagbar -t warning -m 'You pressed the exit shortcut. Do you really want to exit i3? This will end your X session.' -B 'Yes, exit i3' 'i3-msg exit'\u0026quot; # resize window (you can also use the mouse for that) mode \u0026quot;resize\u0026quot; { bindsym Left resize shrink width 5 px or 5 ppt bindsym Down resize grow height 5 px or 5 ppt bindsym Up resize shrink height 5 px or 5 ppt bindsym Right resize grow width 5 px or 5 ppt bindsym Return mode \u0026quot;default\u0026quot; } bindsym $mod+r mode \u0026quot;resize\u0026quot; # panel bar { colors { background #2f343f statusline #2f343f separator #4b5262 # colour of border, background, and text focused_workspace #2f343f #bf616a #d8dee8 active_workspace #2f343f #2f343f #d8dee8 inactive_workspace #2f343f #2f343f #d8dee8 urgent_workspacei #2f343f #ebcb8b #2f343f } status_command i3status } # gaps gaps top 20 gaps left 10 gaps right 10 gaps bottom 10 gaps inner 25 border_radius 10 # Hide edge borders only if there is one window with no gaps hide_edge_borders smart_no_gaps # reload exec_always hsetroot -solid \u0026quot;#F1CCBB\u0026quot;    6. Some tricks and tips #    A trick with terminal emulator:\n Disable scrollbar and menubar.           Configure padding for vte-terminal.    1mkdir -p ~/.config/gtk-3.0 2cat \u0026lt;\u0026lt;EOT \u0026gt;\u0026gt; ~/.config/gtk-3.0/gtk.css 3vte-terminal { 4padding: 30px; 5} 6EOT  Result.      7. References #   https://www.lifewire.com/window-manager-vs-the-desktop-environment-in-linux-4588338 https://en.wikipedia.org/wiki/X_window_manager https://i3wm.org/docs https://wiki.archlinux.org/title/i3  "},{"id":1,"href":"/blog/posts/getting-started-tiling-wm-part-2-rofi/","title":"Getting Started with Tiling WM [Part 2] - Rofi","section":"Posts","content":"In the part1, I\u0026rsquo;ve used rofi instead of dmenu. This part will show you how to start with rofi.  1. Introduction #   Rofi is a window switcher, application launcher and dmenu replacement. Features:  Fully configurable keyboard navigation. Type to filer. Built-in modes:  Window switcher mode. Application laucher. Desktop file application launcher. SSH laucher mode.   History-based ordering. \u0026hellip;    2. Getting started #   Installing rofi is quite easy.  1sudo apt install rofi -y  Run it for the first time.  1rofi -lines 12 -padding 18 -width 60 -location 0 -show drun -sidebar-mode -columns 3 -font \u0026#39;DejaVu Sans 8\u0026#39;   Expand ↕  1 -show mode 2 3 Open rofi in a certain mode. Available modes are window, run, drun, ssh, combi. The 4 special argument keys can be used to open a searchable list of supported key bind‐ 5 ings (see KEY BINDINGS) 6 7 To show the run-dialog: 8 9 rofi -show run 10 11 -lines 12 13 Maximum number of lines to show before scrolling. 14 15 rofi -lines 25 16 17 Default: 15 18 19 -location 20 21 Specify where the window should be located. The numbers map to the following loca‐ 22 tions on screen: 23 24 1 2 3 25 8 0 4 26 7 6 5 27 28 Default: 0 29 30 -padding 31 32 Define the inner margin of the window. 33 34 Default: 5 35 36 -sidebar-mode 37 38 Open in sidebar-mode. In this mode a list of all enabled modes is shown at the bot‐ 39 tom. (See -modi option) To show sidebar, use: 40 41 rofi -show run -sidebar-mode -lines 0 42              Press hot key (defined in i3 configuration file) \u0026lt;Window\u0026gt;+d to start rofi. Use \u0026lt;Shift\u0026gt;+\u0026lt;left/right\u0026gt; to switch between mode. More details you can found in rofi github.  3. Tweaking #   The default setup looks quite boring. Let\u0026rsquo;s tweak a bit! There are currently three methods of setting configuration options:  Local configuration. Normally, depending on XDG, in ~/.config/rofi/config. This uses the Xresources format. Xresources: A method of storing key values in the Xserver. See here for more information. Command line options: Arguments are passed to Rofi.   We will use configuration file.  1mkdir -p ~/.config/rofi/themes 2touch ~/.config/rofi/themes/onedark.theme  Copy the follow content into ~/.config/rofi/themes/onedark.theme:  configuration { show-icons: true; font: \u0026quot;DejaVu Sans Mono 10\u0026quot;; modi: \u0026quot;window,run,drun\u0026quot;; } * { background: #282c34; foreground: #abb2bf; background-color: @background; selected-normal-foreground: @foreground; selected-normal-background: #98c379; selected-urgent-background: #e5c07b; selected-urgent-foreground: @foreground; border: 5; lines: 12; padding: 0; margin: 0; spacing: 0; } window { width: 50%; transparency: \u0026quot;real\u0026quot;; } mainbox { children: [inputbar, listview]; } listview { columns: 1; } element { padding: 12; orientation: vertical; text-color: @foreground; } element selected { background-color: @selected-normal-background; text-color: @background; } inputbar { background-color: @background; children: [prompt, entry]; } prompt { enabled: true; font: \u0026quot;DejaVu Sans Mono 10\u0026quot;; padding: 12 0 0 12; text-color: @selected-urgent-background; } entry { padding: 12; text-color: @selected-urgent-background; }  Run it and you can see the magic!  1rofi -theme ~/.config/rofi/themes/onedark.theme -show drun       Don\u0026rsquo;t forget to update hotkey in i3 configuration file.  bindsym $mod+d exec rofi -theme ~/.config/rofi/themes/onedark.theme -show drun "},{"id":2,"href":"/blog/posts/getting-started-tiling-wm-part-3-polybar/","title":"Getting Started with Tiling WM [Part 3] - Polybar","section":"Posts","content":"1. Overview #  According to Polybar frontpage, Polybar is A fast and easy to use tool for creating status bars .\nWIP  "},{"id":3,"href":"/blog/posts/getting-started-tiling-wm-part-4-xresources/","title":"Getting Started with Tiling WM [Part 4] - Xresources","section":"Posts","content":"WIP  "},{"id":4,"href":"/blog/posts/getting-started-tiling-wm-part-5-compton/","title":"Getting Started with Tiling WM [Part 5] - Compton","section":"Posts","content":"WIP  "},{"id":5,"href":"/blog/posts/linux-tools-that-you-never-knew-you-needed/","title":"Linux tools that you never knew you needed","section":"Posts","content":"1. bat - (cat alternative) #   bat: A cat(1) clone with syntax highlighting and Git integration. Example:      2. fd - (find alternative) #   fd: a simple, fast and user-friendly alternative to find. Examples:      3. httpie - (wget/curl alternative) #   httpie: a user-friendly command-line HTTP client for the API era. It comes with JSON support, syntax highlighting, persistent sessions, wget-like downloads, plugins, and more. Examples:  1# Hello world 2$ http httpie.io/hello 3# Custom HTTP method, HTTP headers and JSON data 4$ http PUT pie.dev/put X-API-Token:123 name=John 5# Submitting forms 6$ http -f POST pie.dev/post hello=World 7# Upload a file using redirect input 8$ http pie.dev/post \u0026lt; files/data.json 9# ... 10# For more examples, check out: https://httpie.io 4. ripgrep - (grep alternative) #   ripgrep: a faster grep. ripgrep is a line-oriented search tool that recursively searches your current directory for a regex pattern. By default, ripgrep will respect your .gitignore and automatically skip hidden files/directories and binary files. Benchmark. Examples:  1# Basic use 2$ rg fast README.md 3# Regular expressions 4$ rg \u0026#39;fast\\w+\u0026#39; README.md 5# Recursive search - recursively searching the directory (current directory is default) 6$ rg \u0026#39;fn write\\(\u0026#39; 7# ... 8# For more examples, checkout: https://github.com/BurntSushi/ripgrep/blob/master/GUIDE.md 5. delta #   delta: Code evolves, and we all spend time studying diffs. Delta aims to make this both efficient and enjoyable: it allows you to make extensive changes to the layout and styling of diffs, as well as allowing you to stay arbitrarily close to the default git/diff output. Diff/git diff doesn\u0026rsquo;t show you exactly what was changed.       Delta shows within-line highlights based on a Levenshtein edit inference algorithm.       By default, delta restructures the git output slightly to make the hunk markers human-readable:       Example config:  1[core] 2 pager = delta 3 4[delta] 5 plus-style = \u0026#34;syntax #98c379\u0026#34; 6 minus-style = \u0026#34;syntax #e06c75\u0026#34; 7 syntax-theme = OneHalfDark 8 navigate = true 9 features = line-numbers decorations 10 11[interactive] 12 diffFilter = delta --color-only  Completely replace diff with delta:  1alias diff=\u0026#34;delta\u0026#34; 6. z #   Tired for cding into the same directories over and over? Save your time with z command! z: jump around. Z is a shell script that makes jumping around your file directory pleasantly simple. Instead of trying to remember the exact path of where you need to go, or worse, cding into the next directory followed by lsing and then cding again over and over (we’ve all been there), Z allows you to “lazy type” where you want to go and it’ll handle the rest. Examples:  1# Takes me to my workspace folder from anywhere. 2$ z workspace 7. fzf #   fzf: fzf is a general-purpose command-line fuzzy finder. It\u0026rsquo;s an interactive Unix filter for command-line that can be used with any list; files, command history, processes, hostnames, bookmarks, git commits, etc. Examples:  1# Read the list from STDIN and write the selected item to STDOUT 2$ find * -type f | fzf \u0026gt; selected 3$ vim $(fzf) 4# COMMAND **\u0026lt;TAB\u0026gt; 5# Files under the current directory 6# - You can select multiple items with TAB key 7$ vim **\u0026lt;TAB\u0026gt; 8 9# Files under parent directory 10$ vim ../**\u0026lt;TAB\u0026gt; 11 12# Files under parent directory that match `fzf` 13$ vim ../fzf**\u0026lt;TAB\u0026gt; 14 15# Files under your home directory 16$ vim ~/**\u0026lt;TAB\u0026gt; 17 18 19# Directories under current directory (single-selection) 20$ cd **\u0026lt;TAB\u0026gt; 21 22# Directories under ~/github that match `fzf` 23$ cd ~/github/fzf**\u0026lt;TAB\u0026gt; 24 25# Can select multiple processes with \u0026lt;TAB\u0026gt; or \u0026lt;Shift-TAB\u0026gt; keys 26$ kill -9 \u0026lt;TAB\u0026gt; 27 28$ unset **\u0026lt;TAB\u0026gt; 29$ export **\u0026lt;TAB\u0026gt; 30$ unalias **\u0026lt;TAB\u0026gt; 31# ... 32# For more examples, checkout: https://github.com/junegunn/fzf          8. thefuck #   thefuck: Magnificent app which corrects your previous console command.       Examples:  1$ apt-get install vim 2E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied) 3E: Unable to lock the administration directory (/var/lib/dpkg/), are you root? 4 5$ fuck 6sudo apt-get install vim [enter/↑/↓/ctrl+c] 7Reading package lists... Done 8... 9# ... 10# For more examples, check out: https://github.com/nvbn/thefuck 9. exa - (ls alternative) #   exa: A modern replacement for ls. exa is an improved file lister with more features and better defaults. It uses colours to distinguish file types and metadata. It knows about symlinks, extended attributes, and Git. And it’s small, fast, and just one single binary. Examples:       Completely replace ls with exa:  1alias ls=\u0026#34;exa\u0026#34;      "},{"id":6,"href":"/blog/posts/set-animated-gif-as-wallpaper/","title":"Set Animated Gif as Wallpaper","section":"Posts","content":" NOTE: Environment Ubuntu 20.04\n Dependencies #   Xwinwrap:  1sudo apt-get install xorg-dev build-essential libx11-dev x11proto-xext-dev libxrender-dev libxext-dev 2git clone https://github.com/ujjwal96/xwinwrap.git 3cd xwinwrap 4make 5sudo make install 6make clean  Gifsicle:  1sudo apt install gifsicle The helper script #  A helper script to setup animated .gif in dual monitors.\n1#!/bin/bash 2# Uses xwinwrap to display given animated .gif in dual monitors. 3if [ $# -ne 1 ]; then 4 echo 1\u0026gt;\u0026amp;2 Usage: $0 image.gif 5 exit 1 6fi 7gif=$1 8killall -9 xwinwrap 9killall -9 gifview 10# Get monitors resolution 11SCR1=`xrandr | awk \u0026#39;/primary/ \u0026amp;\u0026amp; /connected/ { print $4 }\u0026#39;` 12SCR2=`xrandr | awk \u0026#39;!/primary/ \u0026amp;\u0026amp; /connected/ { print $3 }\u0026#39;` 13 14xwinwrap -g $SCR1 -ov -ni -s -nf -- gifview -w WID $gif -a \u0026amp; 15xwinwrap -g $SCR2 -ov -ni -s -nf -- gifview -w WID $gif -a \u0026amp; If you want to run xwinwrap by yourself, here is the example:\n1xwinwrap -g 1920x1080 -ov -ni -s -nf -- gifview -w WID /full/path/to/gif -a "},{"id":7,"href":"/blog/posts/linux-swap-space-note/","title":"Swap space note","section":"Posts","content":"1. What is Swap? #  Swap file systems support virtual memory, data is written to a swap file system when there is not enough RAM to store the data your system is processing.\n2. Swap partition size #  2.1. Old rule of thumb #  swap = 2 * the-amount-of-RAM So if a computer had 64KB of RAM, a swap partition of 128KB would be an optimum size. This rule took into the facts that RAM sizes were typically quite small at the time. Nowadays, RAM has become a cheap \u0026amp; affordable commondity, so the 2x rule is outdated.\n2.2. What is the right amount of swap space? #  Choosing the correct swap size is important. Too much swap space can hide memory leaks, also the storage space is allocated but idle. It can affect the system performance in general.\nFollow the RedHat (CentOS 7x \u0026amp; RHEL 7) guide, the recommended size of a swap partition depending on the amount of RAM \u0026amp; whether you want sufficient memory for your system.\nswap \u0026lt;= 10% * total-size-hard-drives \u0026amp;\u0026amp; swap \u0026lt;= 128GB (if hibernation is allowed)    Amount of RAM Recommended swap space Recommended swap space if allowing for hibernation     \u0026lt; 2GB 2 * the-amount-of-RAM 3 * the-amount-of-RAM   \u0026gt; 2GB - 8GB the-amount-of-RAM 2 * the-amount-of-RAM   \u0026gt; 8GB - 64GB \u0026gt;= 4GB 1.5 * the-amount-of-RAM   \u0026gt; 64GB \u0026gt;= 4GB Hibernation not recommended    3. Common misconceptions \u0026amp; gotchas #  3.1. Increasing swap size would increase performance #   No, it wouldn\u0026rsquo;t. Remember that the slowest part of memory is your hard-disk - swap just provides the ability to use more memory by swapping some pages out to the disk, which is slow compared to RAM operations. Swap can also increase disk I/O \u0026amp; CPU load. This is a tradeoff. Without swap, the OOM may get you. It causes a downtime and in the real life scenario, the application can be slow a bit rather than down completely.  3.2. Swappiness #    The linux kernel tunable parameter vm.swappiness (/proc/sys/vm/swappiness) can be used to define how aggressively memory pages are swapped to disk.\n  The default value: 60. The lower the value, the less swapping is used \u0026amp; the more memory pages are kept in the physical memory.\n* 0: swap is disable. * 1: minimum amount of swapping without disabling it entirely. * 10: recommended value to improve performance when sufficient memory exists in a system * 100: aggressive swapping   Useful commands:\n1# Check the current value 2sysctl vm.swappiness 3# Adjust the value 4echo 10 \u0026gt; /proc/sys/vm/swappiness 5sysctl -w vm.swappiness=10 6echo \u0026#34;vm.swappiness = 10\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf   On SSDs, swapping out anonymous pages and reclaiming file pages are essentially equivalent in terms of performance/latency. On older spinning disks, swap reads are slower due to random reads, so a lower vm.swappiness setting makes sense there.\n  3.3. Using swap as emergency memory #   Swap is not generally about getting emergency memory, it\u0026rsquo;s about making memory reclamation egalitarian and efficient. In fact, using it as \u0026ldquo;emergency memory\u0026rdquo; is generally actively harmful.  4. References #    RedHad guideline\n  Chris Down\u0026rsquo;s post\n  Linux Hint - Understanding vm.swappiness\n  "},{"id":8,"href":"/blog/posts/ansitheus/","title":"Ansitheus","section":"Posts","content":"1Ansitheus = Ansible + Prometheus 1. Prometheus overview #   NOTE: Checkout the Prometheus official documentation.\n Prometheus is an open-source systems monitoring \u0026amp; alerting toolkit originally built at SoundCloud.\n1.1. Features #   a multi-dimensional data model with time series data identified by metric name \u0026amp; key/value pairs PromQL, a flexible query language to leverage this dimensionality no reliance on distributed storage; single server nodes are autonomous time series collection happens via a pull model over HTTP pushing time series is supported via an intermediary gateway targets are discovered via service discovery or static configuration multiple modes of graphing \u0026amp; dashboarding support  1.2. Architecture \u0026amp; components #  Prometheus scrapes metrics from instrumented jobs, either directly or via an intermediary push gateway for short-lived jobs. It stores all scraped samples locally \u0026amp; runs rules over this data to either aggregate \u0026amp; record new time series from existing data or generate alerts. Grafana or other API consumers can be used to visualize the collected data.\n Prometheus server: scrapes \u0026amp; stores time series data. Prometheus alertmanager: handle alerts. Special-purpose exporters. Push-gateway: support short-lived jobs. client libraries: instrument application code. Various support tools: Grafana,\u0026hellip;  2. Ansitheus #  2.1. Why Ansitheus? #  As you can see that, Prometheus ecosystem consists of multiple components. The operator may need a lot of efforts to configure, deploy \u0026amp; maintain these components. To make life easier, it is necessary to enter the world of automation, using modern tools of configuration management, provisioning \u0026amp; orchestration. Ansible is one of them. It is simple, agentless IT automation that anyone can use. My team decided to choose it as the automation solution, \u0026amp; Ansitheus is the result.\n2.2. Features #  The idea using Ansible to deploy Prometheus is not new. There are many existing solutions:\n cloudalchemy/ansible-prometheus ernestas-poskus/ansible-prometheus \u0026hellip;  So what makes Ansitheus be different with others?\n Deploy, configure \u0026amp; maintain the Prometheus ecosystem easily. Allow users to configure, deploy the system from scratch:  Prepare, configure the local repository. Install the necessary packages. Configure Docker private registry. Configure Docker daemon.   Containerize Prometheus components:  Docker is hotter than hot because it makes it possible to get far more apps running on the same old servers \u0026amp; it also makes it very easy to package \u0026amp; ship programs. You can easily find the advantages of Docker \u0026amp; container through internet.   High availability with HAProxy \u0026amp; Keepalived. Support centralized Docker logging with Fluentd. Support Ansible vault to work with sensitive data.  2.3. Components #   Prometheus Server Prometheus Alertmanager Prometheus Node-exporter Google Cadvisor Prometheus SNMP exporter Haproxy Keepalived Fluentd Grafana Other Prometheus exporters - TODO  2.4. Getting started #    Install Ansible in deployment node.\n  Clone this repostiory.\n  Create configuration directory, default path /etc/ansitheus.\n1sudo mkdir -p /etc/ansitheus 2sudo chown $USER:$USER /etc/ansitheus   Copy config.yml to /etc/ansitheus directory - this is the main configuration for Ansible monitoring tool.\n1cp /path/to/ansitheus/repository/etc/ansitheus/config.yml \\ 2 /etc/ansitheus/config.yml   Copy inventory files to the current directory.\n1cp /path/to/ansitheus/repository/ansible/inventory/* .   Modify inventory \u0026amp; /etc/ansitheus/config.yml.\n  Run tools/ansitheus, figure out yourself:\n1Usage: ./tools/ansitheus COMMAND [option] 2 3Options: 4 --inventory, -i \u0026lt;inventory_path\u0026gt; Specify path to ansible inventory file 5 --configdir, -c \u0026lt;config_path\u0026gt; Specify path to directory with config.yml 6 --verbose, -v Increase verbosity of ansible-playbook 7 --tags, -t \u0026lt;tags\u0026gt; Only run plays \u0026amp; tasks tagged with these values 8 --help, -h Show this usage information 9 --skip-common Skip common role 10 --ask-vault-pass Ask for vault password 11 12Commands: 13 precheck Do pre-deployment checks for hosts 14 deploy Deploy \u0026amp; start all ansitheus containers 15 pull Pull all images for containers (only pull, no running containers) 16 destroy Destroy Prometheus containers \u0026amp; service configuration 17 --include-images to also destroy Prometheus images 18 --include-volumes to also destroy Prometheus volumes 19   2.5. Contributors #   Kien Nguyen Dat Vu Duc Nguyen Long Cao  "},{"id":9,"href":"/blog/posts/operate-etcd-cluster/","title":"Operate Etcd cluster","section":"Posts","content":" NOTE: This is my perspective aggregation. You can easily find these such of knowledges in the references.\n 1. Context #  Etcd Version v3.4.0.\n2. Requirements #  2.1. Number of nodes #   \u0026gt;= 3 nodes. A etcd cluster needs a majority of nodes, a quorum to agree on updates to the cluster state. For a cluster with n-members, quorum is (n/2)+1.  2.2. CPUs #   Etcd doesn\u0026rsquo;t require a lot of CPU capacity. Typical clusters need 2-4 cores to run smoothly.  2.3. Memory #   Etcd performance depends on having enough memory (cache key-value data, tracking watchers\u0026hellip;). Typical 8GB is enough.  2.4. Disk #   An etcd cluster is very sensitive to disk latencies. Since etcd must persist proposals to its log, disk activity from other processes may cause long fsync latencies. The upshot is etcd may miss heartbeats, causing request timeouts and temporary leader loss. An etcd server can sometimes stably run alongside these processes when given a high disk priority. Check whether a disk is fast enough for etcd using fio. If the 99th percentile of fdatasync is \u0026lt;10ms, your storage is ok.  1$ fio --rw=write --ioengine=sync --fdatasync=1 --directory=test-data \\ 2 --size=22m --bs=2300 --name=mytest  SSD is recommended.  2.5. Network #   Etcd cluster should be deployed in a fast and reliable network. Low latency ensures etcd members can communicate fast. High bandwidth can reduce the time to recover a failed etcd member. 1GbE is sufficient for common etcd. Note that the network isn\u0026rsquo;t the only source of latency. Each request and response may be impacted by slow disks on both the leader and followers.  3. Tuning #  3.1. Time parameters #   Heartbeat interval.  The frequency with which the leader will notify followers that it is still the leader. Default: 100ms. Best practice: Around 0.5-1.5 x round-trip time (RTT) between members. Measure RTT with ping. Tradeoff: Too low -\u0026gt; etcd will send unnecessary messages -\u0026gt; increase the usage of CPU and network resources. Too high -\u0026gt; leads to high election timeout.   Election timeout.  How long a follower node will go without hearing a heartbeat before attempting to become leader itself. Default: 1000ms. Best practice: \u0026gt;= 10 x RTT and \u0026lt; 50s.   The heartbeat interval and election timeout value should be the same for all members in one cluster.  1# Command line arguments: 2$ etcd --heartbeat-interval=100 --election-timeout=500 3 4# Environment variables: 5$ ETCD_HEARTBEAT_INTERVAL=100 ETCD_ELECTION_TIMEOUT=500 etcd 3.2. Disk #   An etcd server can sometimes stably run alongside these processes when given a high disk priority using ionice.  1# best effort, highest priority 2$ sudo ionice -c2 -n0 -p `pgrep etcd` 3.3. Snapshot #   etcd appends all key changes to a log file -\u0026gt; huge log that grows forever ☝️ Solution: Make periodic snapshots (save the current and remove old logs). Default: make snapshots after every 10 000 changes. Tuning: Just in case that etcd\u0026rsquo;s memory and disk usage is too high, lower threshold.  1# Command line arguments: 2$ etcd --snapshot-count=5000 3 4# Environment variables: 5$ ETCD_SNAPSHOT_COUNT=5000 etcd 4. Maintenance #  4.1. History compaction #   Etcd keeps an exact history of its keyspace, the history should be periodically compacted to avoid performance degradation and eventual storage space exhaustion. Etcd can be set to automatically compact the keyspace with the --auto-compaction-* option with a period of hours.  1# keep one hour of history 2$ etcd --auto-compaction-retention=1 --auto-compaction-mode=periodic  Compaction modes:  Revision-based: --auto-compaction-mode=revision --auto-compaction-retention=1000 automatically Compact on \u0026ldquo;latest revision\u0026rdquo; - 1000 every 5-minute (when latest revision is 30000, compact on revision 29000). Use this when having a large keyspace. Periodic: --auto-compaction-mode=periodic --auto-compaction-retention=72h automatically Compact with 72-hour retention window every 1-hour. Use this when having a huge number of revisions for a key-value pair.    4.2. Defragmentation #   Compacting old revisions internally fragments etcd by leaving gaps in backend database - internal fragmentation. Internal fragmentation space is available for use by etcd but unavailable to the host filesystem. Solution: Release this space back to the filesystem with defrag.  1$ etcdctl defrag  It should be run rather infrequently, as there is always going to be an unavoidable pause.  5. References #   Etcd hardware: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md Etcd tuning: https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md Etcd maintainence: https://etcd.io/docs/v3.4.0/op-guide/maintenance/  "},{"id":10,"href":"/blog/posts/golang-block-forever/","title":"Golang: Block forever","section":"Posts","content":"Sometimes, you want to block the current goroutine when allowing others to continue. Here is some tricks I\u0026rsquo;ve collected:\n1. References #  Firstly give them some credits:\n https://blog.sgmansfield.com/2016/06/how-to-block-forever-in-go/ https://pliutau.com/different-ways-to-block-go-runtime-forever/   NOTE: I run these with Golang 1.12\n 2. The original #  1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func show() { 6 for i := 1; i \u0026lt; 9696969; i++ { 7 time.Sleep(1000) 8 fmt.Println(i) 9 } 10} 11 12func main() { 13 go show() // The main goroutine is exited before the show() be done. 14 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 15} 3. Bad - An empty infinite loop #  1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func forever() { 9 for { 10 // Empty, just do nothing 11 } 12} 13 14func show() { 15 for i := 1; i \u0026lt; 9696969; i++ { 16 time.Sleep(5 * time.Second) 17 fmt.Println(i) 18 } 19} 20 21func main() { 22 go show() 23 forever() 24 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 25} An infinite loop here is a busy loop that does nothing except burn CPU time.\n4. Good - Busy blocking #  1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;runtime\u0026#34; 6 \u0026#34;time\u0026#34; 7) 8 9func forever() { 10 for { 11 runtime.Gosched() 12 } 13} 14 15func show() { 16 for i := 1; i \u0026lt; 9696969; i++ { 17 time.Sleep(5 * time.Second) 18 fmt.Println(i) 19 } 20} 21 22func main() { 23 go show() 24 forever() 25 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 26} It will reduce your CPU usage but it isn\u0026rsquo;t the preferable solution.\n5. Good - Waiting on itself #  We wait but we never done XD\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;sync\u0026#34; 6 \u0026#34;time\u0026#34; 7) 8 9func forever() { 10 wg := sync.WaitGroup{} 11 wg.Add(1) 12 wg.Wait() 13} 14 15func show() { 16 for i := 1; i \u0026lt; 9696969; i++ { 17 time.Sleep(5 * time.Second) 18 fmt.Println(i) 19 } 20} 21 22func main() { 23 go show() 24 forever() 25 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 26} 6. Good - Empty select #  1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func forever() { 9 select{ } 10} 11 12func show() { 13 for i := 1; i \u0026lt; 9696969; i++ { 14 time.Sleep(5 * time.Second) 15 fmt.Println(i) 16 } 17} 18 19func main() { 20 go show() 21 forever() 22 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 23} 7. Good - Double locking #  1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;sync\u0026#34; 6 \u0026#34;time\u0026#34; 7) 8 9func forever() { 10 m := sync.Mutex{} // Same with sync.RWMutex 11 m.Lock() 12 m.Lock() 13} 14 15func show() { 16 for i := 1; i \u0026lt; 9696969; i++ { 17 time.Sleep(5 * time.Second) 18 fmt.Println(i) 19 } 20} 21 22func main() { 23 go show() 24 forever() 25 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 26} 8. Good - Reading an Empty Channel #  1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func forever() { 9 c := make(chan struct{}) 10 \u0026lt;-c 11} 12 13func show() { 14 for i := 1; i \u0026lt; 9696969; i++ { 15 time.Sleep(5 * time.Second) 16 fmt.Println(i) 17 } 18} 19 20func main() { 21 go show() 22 forever() 23 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 24} 9. Good - Self produce-and-consume #  1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func forever() { 9 c := make(chan struct{}, 1) 10 for { 11 select { 12 case \u0026lt;-c: 13 case c \u0026lt;- struct{}{}: 14 } 15 } 16} 17 18func show() { 19 for i := 1; i \u0026lt; 9696969; i++ { 20 time.Sleep(5 * time.Second) 21 fmt.Println(i) 22 } 23} 24 25func main() { 26 go show() 27 forever() 28 fmt.Println(\u0026#34;OK we\u0026#39;re done\u0026#34;) 29} "},{"id":11,"href":"/blog/posts/rip-kobe-bryant/","title":"Rest In Peace Kobe Bryant","section":"Posts","content":"Source: The Undefeated\nI am not Kobe fan honestly but just like him, basketball is something I love. I hope he\u0026rsquo;s at peace because although his journey in life is over, the legacy he left behind is etched in all our souls.\nRest In Peace Mamba 🏀\n"},{"id":12,"href":"/blog/posts/target-2020/","title":"Mục tiêu 2020","section":"Posts","content":"Tổng kết 2019 #  Mục tiêu 2019:\n Viết mục tiêu cho 2019 Kỹ năng:  Sử dụng thành thạo và ứng dụng Golang vào project thực tết. \u0026gt;=1000 commits trên Github. Hey yooooooo! 🎉 Học về cách thiết kế một hệ thống phân tán giải quyết bài toán thật -\u0026gt; Vẫn nửa vời :( Đưa Kubernetes vào ứng dụng thực tế. Củng cố thêm kiến thức đã có hiện tại, nhưng chưa đủ 😢 Thất bại hoàn toàn: Dành thêm thời gian OpenStack (Kolla-Ansible, Zun,\u0026hellip;)   Sách: 20-30 cuốn sách (sách gì cũng được, truyện trinh thám, văn học kinh điển, tech book). Du lịch: Quảng Bình - Hải Phòng - Thượng Hải\u0026hellip; Thể thao: Một câu chuyện buồn\u0026hellip; Blog (là cái này nè): Buồn tiếp. Nhạc nhẽo: Buồn tiếp^2, mới tập sơ sơ ukulele, chưa ưng ý. Chụp ảnh: Buồn tiếp^3.  via GIPHY\n  Qua một năm viết ra những mục tiêu, mình nhận thấy một điều rằng không chỉ mình lười, mình còn chẳng biết thực sự mình sống và làm việc để hướng đến điều gì. Vật chất, hay hiện thực hóa chính là tiền, nhà cửa, xe cộ, mình có thể đạt được không sớm thì muộn. Nhưng sau đó sẽ hướng đến gì tiếp theo? via GIPHY\nNhưng nếu bạn còn không biết bản thân muốn gì vậy làm thế nào để theo đuổi?\n Mục tiêu 2020 #  via GIPHY\nViết tạm ra đây trước, trước tiên mình phải tìm được câu trả lời cho câu hỏi phía trên đã.\n Kỹ năng:  Phát huy những gì đã làm được từ năm trước. Học về kỹ năng căn bản tốt hơn, ít nhất là tốt cho interview.   Du lịch:  Miền Tây Nam Bộ, yup!!!! Lào? (Maybe) Phan Rang/Lý Sơn. Huế. Hải Phòng.   Sách: Đọc thêm sách Tech. Thể thao:  Tiếp tục cố gắng chơi bóng rổ. Ballin' 🏀 Tiếp tục tập Workout - giữ vững nhịp tập thể dục buổi chiều.   Chụp ảnh: Cần xác định rõ liệu còn yêu thích nhiếp ảnh không? Hay chỉ là sở thích nhất thời. Tiếng Anh: Tiếng Anh mình thật sự tệ, cần phải đi học tiếng Anh nghiêm túc. Ít nhất là tiếng Anh giao tiếp, tránh việc nói chuyện bị khớp. Công việc: Suy nghĩ thực sự về một cơ hội phát triển bản thân khác. Có thể nhảy việc, có thể làm thêm bên ngoài (đúng hoặc trái ngành). Nhà cửa/xe cộ: Cái này có thể quá tầm với nhưng cứ viết đây để cố gắng.  "},{"id":13,"href":"/blog/posts/blog-guideline/","title":"Blog Guideline","section":"Posts","content":"In the beginning, I supposed that I\u0026rsquo;m the only one who write-up thing in this blog. But now thing was change, this blog might have multiple bloggers. So it needs a guideline to describe how to contribute.\n1. How to submit a new content #   Here is the source repo. Fork it \u0026amp; start writing. Create a pull request to submit your content. Make sure to create your author page.  2. Create an author page #    Create a directory under content/authors, name it as your desire nickname. For example, your name is amazingblogger.\n  Directory structure.\n  1~/Documents/blog master $? via ⬢ v8.10.0 took 6s tree content/authors 2content/authors 3├── donghm 4│ ├── avatar.jpg 5│ └── index.md 6├── _index.md 7└── kiennt 8 ├── avatar.jpg 9 └── index.md 10└── amazingblogger ## Here 11 ├── avatar.jpg 12 └── index.md  Write about yourself in index.md.  1--- 2name: \u0026#34;Amazing Blogger\u0026#34; 3contact: 4 twitter: \u0026#34;@blogger\u0026#34; 5 facebook: \u0026#34;blogger\u0026#34; 6 github: \u0026#34;blogger\u0026#34; 7 email: \u0026#34;blogger@gmail.com\u0026#34; 8website: \u0026#34;https://blogger.io/\u0026#34; 9--- 10 11Your amazing personal page here  Don\u0026rsquo;t forget to place your avatar in directory. The picture format should be jpg or png, no name restriction.  3. Write a post #   Very similar with author page, just place your post under content/posts.  1$ hugo new content/posts/a-new-post.md -t sam  A sample post.  1--- 2title: \u0026#34;Blog Guideline\u0026#34; 3date: 2019-08-22T14:40:59+07:00 4comments: true 5authors: 6 - kiennt 7showDate: true 8tags: [\u0026#34;blog\u0026#34;, \u0026#34;tech\u0026#34;] 9---  Multiple authors feature is supported. You can disable or enable comment section with comment option. You might want to take look at how I create comment section. Don\u0026rsquo;t forget to add a tag.  4. Create a photo/art gallery #  Hmm, this is my secret corner, so\u0026hellip; Might be in future?\n5. Scripts #  You can notice that some shell scripts are placed in repository. You can only use these if you\u0026rsquo;re the repository collaborator. Just send me a request! 😄\n5.1. Lazy pull #  Just a script to init and update submodule, do git pull (both master and gh-pages branchs).\n5.2. Publish to github page #  I deploy the blog from gh-pages branch. You can also tell Github pages to treat your master branch as the published site or point to a separate gh-pages branch. The latter approach is a bit more complex but has some advantages:\n It keeps your source and generated website in different branches and therefore maintains version control history for both. Unlike the preceding docs/ option, it uses the default public folder.  The publish_to_ghpages.sh automates the set up steps.\n"},{"id":14,"href":"/blog/authors/","title":"Authors","section":"About","content":"Welcome to the author section!\n"},{"id":15,"href":"/blog/posts/openstack-autoscaling-new-approach/","title":"Openstack Autoscaling New Approach","section":"Posts","content":" NOTE(kiennt): There is a legacy Faythe guideline. The new version is coming soon, check its repository for status.\n This guide describes how to automatically scale out your Compute instances in response to heavy system usage. By combining with Prometheus pre-defined rules that consider factors such as CPU or memory usage, you can configure OpenStack Orchestration (Heat) to add and remove additional instances automatically, when they are needed.\n1. The standard OpenStack Autoscaling approach #  Let\u0026rsquo;s talk about the standard OpenStack Autoscaling approach before goes to the new approach.\n1.1. Main components #    Orchestration: The core component providing automatic scaling is Orchestration (heat). Orchestration allows you to define rules using human-readable YAML templates. These rules are applied to evaluate system load based on Telemetry data to find out whether there is need to more instances into the stack. Once the load has dropped, Orchestration can automatically remove the unused instances again.\n  Telemetry: Telemetry does performance monitoring of your OpenStack environment, collecting data on CPU, storage and memory utilization for instances and physical hosts. Orchestration templates examine Telemetry data to access whether any pre-defined action should start.\n Ceilometer: a data collection service that provides the ability to normalise and transform data across all current OpenStack core components with work underway to support future OpenStack components. Gnocchi: provides a time-series resource indexing, metric storage service with enables users to capture OpenStack resources and the metrics associated with them. Aodh: enables the abiltity to trigger actions based on defined rules against sample or event data collected by Ceilometer.    1.2. Autoscaling process #  For more details, you could check IBM help documentation\n1.3. Drawbacks #   Ceilometer, Aodh are lacking of contribution. Ceilometer API was deprecated. Either Transform and pipeline was the same state, it means cpu_util will be unusable soon. In the commit message, @sileht - Ceilometer Core reviewer wrote that \u0026ldquo;Also backend like Gnocchi offers a better alternative to compute them\u0026rdquo;. But Aodh still deprecated Gnocchi aggregation API which doesn\u0026rsquo;t support rate:mean. For more details, you can follow the issue I\u0026rsquo;ve opened before. Be honest, I was gave up on it - 3 projects which was tightly related together, one change might cause a sequence and break the whole stack, how can I handle that? Aodh has its own formula to define rule based on Ceilometer metrics (that were stored in Gnocchi). But it isn\u0026rsquo;t correct sometimes cause the wrong scaling action. In reality, I face the case that Rabbitmq was under heavy load due to Ceilometer workload. IMO, Gnocchi documentation is not good enough. It might be a bias personal opinion.  2. The new approach with Faythe #  2.1. The idea #  Actually, this isn\u0026rsquo;t a complete new approach, it still leverages Orchestration (heat) to do scaling action. The different comes from Monitor service.\nTake a look at Rico Lin - Heat\u0026rsquo;s PTL, autoscale slide, basically, Autoscaling is the combination of 3 steps:\n Metering. Alarm. Scale.  OpenStack Telemetry takes care of Metering and Alarm. Ok, the new approach is simply using another service that can take Telemetry roles.\nThe another service is Prometheus stack. The question here is why I chose this?\n Nice query language: Prometheus provides a functional query language called PromQL (Prometheus Query Language) that lets the user select and aggregate time series data in real time. A wide range of exporter: The more exporter the more metrics I can collect and evaluate. Flexibile: Beside the system factor like CPU/Memory usage, I can evaluate any metrics I can collect, for example: JVM metrics. // Take time to investigate about Prometheus and fill it here by yourself  2.2. The implementation #  The ideal architecture\n +--------------------------------------------------+ | | | +-----------------+ +-----------------+ | +---------------------+ | | Instance 1 | | Instance 2 | | | | | | | | | | | | Scrape Metrics | +-----------+ | | +-----------+ | | | Prometheus server Scaling Policy | | | | | | | | +-----------------------+ | +--------------------------------------+ | | | | Heat Stack | +--------------------------------------------------+   Prometheus server scrapes metrics from exporters that launch inside Instance. Prometheus server evaluates metrics with pre-defined rules. Prometheus server fires alert to Prometheus alertmanager. Prometheus alertmanager sends POST Scale request to Heat Scaling policy with webhook configuration.  It\u0026rsquo;s a piece of cake, right? But where is Faythe, I don\u0026rsquo;t see it? Let\u0026rsquo;s talk about the solution problems:\n Prometheus Alertmanager webhook config doesn\u0026rsquo;t support additional HTTP headers. And they won\u0026rsquo;t! 😢 Heat Scaling Policy signal url requires X-Auth-Token in header and Prometheus can\u0026rsquo;t generate a token itself, either. Heat doesn\u0026rsquo;t recognize the resolved alerts from Prometheus Alertmanager to execute scale in action. How to connect these components together?  We need a 3rd service to solve these problems - Faythe does some magic.\nvia GIPHY\n The reality architecture\n ++-------------------------------------------------+ | + | +-----------------+ +-----------------+ | +---------------------+ | | Instance 1 | | Instance 2 | | | | + | | | | | | | Scrape Metrics | +-----------+ | | +-----------+ | | | Prometheus server  NOTE: The stack leverages OpenStack instance metadata and Prometheus labels.\n  Prometheus server scrapes metrics from exporters that launch inside Instance. Prometheus server evaluates metrics with pre-defined rules. Prometheus server fires alert to Prometheus alertmanager. Prometheus alertmanager sends Alerts via pre-configured webhook URL - Faythe endpoint. Faythe receives and processes Alerts (dedup, group alert and generate a Heat signal URL) and creates a POST request to scale endpoint.  2.3. Guideline #  The current aprroach requires some further setup and configuration from Prometheus and Heat stack. You will see that it\u0026rsquo;s quite complicated.\nThe simplify in logic is paid by the complex config steps.\nStep 1: Create a stack - the following is the sample template. It has several requirements:\n OS::Heat::ScalingPolicy has to be named as scaleout_policy and scalein_policy. OS::Heat::AutoScalingGroup\u0026rsquo;s instance metadata has to contain stack_asg_name and stack_asg_id. It will be used to generate signal URL. Instance should have a cloud init script to enable and start Prometheus exporters automatically.  1--- 2resources: 3 asg: 4 type: OS::Heat::AutoScalingGroup 5 properties: 6 min_size: { get_param: min_size } 7 max_size: { get_param: max_size } 8 resource: 9 type: { get_param: service_template } 10 properties: 11 flavor: { get_param: flavor } 12 image: { get_param: image } 13 key_name: { get_param: key_name } 14 network: { get_param: network } 15 subnet: { get_param: subnet } 16 metadata: { 17 \u0026#34;monitoring\u0026#34;: \u0026#34;1\u0026#34;, ## Required 18 \u0026#34;service\u0026#34;: \u0026#34;myservice\u0026#34;, 19 \u0026#34;stack_asg_name\u0026#34;: { get_param: \u0026#34;OS::stack_name\u0026#34; }, ## Required 20 \u0026#34;stack_asg_id\u0026#34;: { get_param: \u0026#34;OS::stack_id\u0026#34; }, ## Required 21 } 22 security_group: { get_param: security_group } 23 24 scaleout_policy: ## Have to be named as `scaleout_policy` 25 type: OS::Heat::ScalingPolicy 26 properties: 27 adjustment_type: change_in_capacity 28 auto_scaling_group_id: { get_resource: asg } 29 cooldown: { get_param: scale_out_cooldown } 30 scaling_adjustment: { get_param: scaling_out_adjustment } 31 32 scalein_policy: ## Have to be named as `scalein_policy` 33 type: OS::Heat::ScalingPolicy 34 properties: 35 adjustment_type: change_in_capacity 36 auto_scaling_group_id: { get_resource: asg } 37 cooldown: { get_param: scale_in_cooldown } 38 scaling_adjustment: { get_param: scaling_in_adjustment } Step 2: Configure Prometheus openstack discovery\n1- job_name: openstack_scale_test 2 openstack_sd_configs: 3 - role: instance 4 identity_endpoint: \u0026#34;\u0026lt;openstackendpoint\u0026gt;\u0026#34; 5 username: \u0026#34;\u0026lt;openstackusername\u0026gt;\u0026#34; 6 password: \u0026#34;\u0026lt;openstackpassword\u0026gt;\u0026#34; 7 domain_name: \u0026#34;default\u0026#34; 8 port: 9100 ## Exporter endpoint 9 refresh_interval: 20s 10 region: \u0026#34;RegionOne\u0026#34; 11 project_name: \u0026#34;\u0026lt;openstackproject\u0026gt;\u0026#34; 12 13 relabel_configs: 14 ## Only keep metrics from ACTIVE instance 15 - source_labels: [__meta_openstack_instance_status] 16 action: keep 17 regex: ACTIVE 18 19 ## Only scrape from instance with monitoring tag 20 - source_labels: [__meta_openstack_tag_monitoring] 21 action: keep 22 regex: 1 23 24 - source_labels: [__meta_openstack_project_id] 25 target_label: project_id 26 replacement: $1 27 28 - source_labels: [__meta_openstack_tag_stack_asg_name] 29 target_label: stack_asg_name 30 replacement: $1 31 32 - source_labels: [__meta_openstack_tag_stack_asg_id] 33 target_label: stack_asg_id 34 replacement: $1 Step 3: Define a Prometheus rule, for example:\n1groups: 2 - name: targets 3 rules: 4 - alert: high_memory_load 5 expr: avg by(stack_asg_id, stack_asg_name, project_id) ((node_memory_MemTotal_bytes{service=\u0026#34;myservice\u0026#34;} - node_memory_MemFree_bytes{service=\u0026#34;myservice\u0026#34;}) / node_memory_MemTotal_bytes{service=\u0026#34;myservice\u0026#34;} * 100) \u0026gt; 80 6 for: 5m 7 labels: 8 severity: critical 9 annotations: 10 summary: \u0026#34;High memory\u0026#34; 11 description: \u0026#34;Instance {{ $labels.instance }} of job {{ $labels.job }} (stack {{ $labels.stack_id }} has been high af for 5m\u0026#34; Step 4: Configure Prometheus Alertmanager webhook, for example:\n1route: 2 receiver: \u0026#34;custom_alert\u0026#34; 3 group_wait: 20s 4 group_interval: 3m 5 6receivers: 7 - name: \u0026#34;custom_alert\u0026#34; 8 webhook_configs: 9 - send_resolved: true 10 url: http://\u0026lt;faythe-host\u0026gt;:\u0026lt;faythe-port\u0026gt;/openstack/autoscaling/openstack-1f 11 http_config: 12 basic_auth: 13 username: \u0026#34;admin\u0026#34; 14 password: \u0026#34;password\u0026#34; Note that, openstack-1f has to be the name of OpenStack configuration group in Faythe config file. It helps Faythe to work with multiple OpenStack.\nStep 5: Configure Faythe\n1## OpenStackConfiguration. 2openstack_configs: 3 openstack-1f: 4 region_name: \u0026#34;RegionOne\u0026#34; 5 domain_name: \u0026#34;Default\u0026#34; 6 auth_url: \u0026#34;\u0026lt;openstackendpoint\u0026gt;\u0026#34; 7 username: \u0026#34;\u0026lt;openstackusername\u0026gt;\u0026#34; 8 password: \u0026#34;\u0026lt;openstackpassword\u0026gt;\u0026#34; 9 project_name: \u0026#34;\u0026lt;openstackproject\u0026gt;\u0026#34; 10 11server_config: 12 ## Example: 13 ## \u0026#34;www.example.com\u0026#34; 14 ## \u0026#34;([a-z]+).domain.com\u0026#34; 15 ## remote_host_pattern: \u0026#34;10.240.202.209.*\u0026#34; 16 basic_auth: 17 username: \u0026#34;admin\u0026#34; 18 password: \u0026#34;password\u0026#34; 19 log_dir: \u0026#34;/whatever/directory/faythe-logs\u0026#34; Step 6: Let\u0026rsquo;s make them work:\n Prometheus server. Prometheus alertmanager. Faythe.  via GIPHY\n 2.4. Drawbacks and TODO #  Drawbacks\n The configuration steps is way too complicated, many manual steps have to be done.  TODO\n Simplify strategy, might need a service discovery.  "},{"id":16,"href":"/blog/gallery/linh-tinh/","title":"Linh Tinh","section":"Gallery","content":"Thỉnh thoảng chụp xong cũng không nhớ chụp hôm nào, chụp về chủ đề gì, tại sao lại chụp. Thôi để tạm đây vậy\u0026hellip;\n  Dsc03518\n      Dscf2553\n      Dscf2555\n      Dscf2558\n      Dscf2580\n      Dscf2589\n      Dscf2605\n      Dscf2613\n      Dscf2637\n      Dscf2638\n      Dscf2642\n      Dscf3001\n      Dscf3035\n      Dscf3036\n      Dscf3037\n      Dscf3038\n      Dscf3041\n      Dscf3045\n      Dscf3051\n      Dscf3057\n      Dscf3061\n      Dscf3067\n      Dscf3077\n      Dscf3078\n      Dscf3079\n      Dscf3111\n      Dscf3112\n     "},{"id":17,"href":"/blog/gallery/sapa-2019/","title":"Sapa 2019","section":"Gallery","content":"Have been friends for a long time but there is the first trip together.\n  Dscf2707\n      Dscf2716\n      Dscf2725\n      Dscf2726\n      Dscf2738\n      Dscf2747\n      Dscf2755\n      Dscf2758\n      Dscf2762\n      Dscf2776\n      Dscf2777\n      Dscf2786\n      Dscf2794\n      Dscf2795\n      Dscf2801\n      Dscf2805\n      Dscf2829\n      Dscf2833\n      Dscf2836\n      Dscf2842\n      Dscf2843\n      Dscf2869\n      Dscf2870\n      Dscf2871\n     "},{"id":18,"href":"/blog/posts/target-2019/","title":"Mục tiêu 2019","section":"Posts","content":"Đến hẹn lại lên, thời điểm Tết đến xuân về, tui lại ngồi copy \u0026amp; paste viết mục tiêu phấn đấu cho năm mới. Tui khá là lười và dễ xao nhãng nên việc viết lên các mục tiêu năm mới đơn giản là một cách tự thúc ép bản thân. \u0026ldquo;Mày đã viết ra những điều này, cố mà làm\u0026rdquo;, kiểu vậy. À khoan, hay không viết nữa nhỉ? Lười quá\u0026hellip;\nvia GIPHY\nNah, năm mới rồi nên thay đổi thôi, chững chạc lên nào! Năm nay tui sẽ viết rõ ràng các mục tiêu mang tính định lượng, không viết chung chung như mọi năm nữa. Yo, let\u0026rsquo;s go!\n Viết mục tiêu cho 2019: checked hihi. Thu nhập:  \u0026lt;salary-2019-per-month\u0026gt; = \u0026lt;salary-2018-per-month\u0026gt; * 1.3.  Kỹ năng: Cái này thì nhiều nè, cứ viết ra một số đầu mục, cập nhật sau.  Sử dụng thành thạo và ứng dụng Golang vào project thực tết.   =1000 commits trên Github.\n  Học về cách thiết kế một hệ thống phân tán giải quyết bài toán thật. Đưa Kubernetes vào ứng dụng thực tế. Củng cố thêm kiến thức đã có hiện tại. Dành thêm thời gian OpenStack (Kolla-Ansible, Zun,\u0026hellip;) \u0026hellip;   Sách: 20-30 cuốn sách (sách gì cũng được, truyện trinh thám, văn học kinh điển, tech book). Du lịch: Biên Hòa - Quảng Bình - Hải Phòng - Sơn La. Thể thao:  Ngày chống đẩy \u0026gt;=80 (à để mai mùng 1 bắt đầu, nay muộn rồi hihi). Dành 2-3 tối trong tuần để chơi bóng rổ.   Blog (là cái này nè): Chăm viết với upload ảnh lên đây hơn. Nhạc nhẽo: Học ít nhất một loại nhạc cụ (ukulele). Chụp ảnh: Dành thêm thời gian cho việc chụp ảnh (Sáng Chủ nhật) để tăng thêm kỹ năng chụp ảnh. Không sợ chụp ở chỗ đông người, tui hay bị ngại\u0026hellip; Còn gì nữa không nhỉ? Có bạn gái!, à tạm thời hết rồi.  Hết rồi, bye! Liệu mà làm đấy Kiên!\nP/s: Btw, năm mới mình vẫn sẽ lười thôi, nhưng sẽ lười một cách chân chính hihi!\nvia GIPHY\n"},{"id":19,"href":"/blog/gallery/29-tet-2019/","title":"Xuân 2019: 29 Tết","section":"Gallery","content":"Một chiều lang thang trên phố Tràng Thi.\n  Dsc03392\n      Dsc03395\n      Dsc03396\n      Dsc03399\n      Dscf2567\n      Dscf2570\n      Dscf2572\n      Dscf2573\n      Dscf2574\n     "},{"id":20,"href":"/blog/gallery/hanoi-hoankiem-longbien/","title":"Hà Nội: Cầu Long Biên - Hồ Hoàn Kiêm","section":"Gallery","content":"Lang thang quanh hồ Hoàn Kiếm, cầu Long Biên\u0026hellip; Vào một ngày hè, cụ thể ngày nào thì quên mất rồi 🙈\n  Dscf0511\n      Dscf0516\n      Dscf0519\n      Dscf0520\n      Dscf0521\n      Dscf0527\n      Dscf0538\n     "},{"id":21,"href":"/blog/posts/lets-comment/","title":"Lets Comment","section":"Posts","content":"Hugo ships with support for Disqus, a third-party service that provides comment and community capabilities to websites via JavaScript. But Disqus generates a shit load of page requests and heavy contents\u0026hellip; which even with the benefits that come with having Disqus in place. People just want something that can be used to post a comment, that is.\nThat\u0026rsquo;s why I choose a Disqus alternative - Utterances. Utterances is a lightweight comments widget built on Github issues. Use Github issues for blog comments, wiki pages and more!\n  Open source. 🙌\n  No tracking, no ads, always free. 📡🚫\n  No lock-in. All data stored in GitHub issues. 🔓\n  Styled with Primer, the css toolkit that powers GitHub. 💅\n  Lightweight. Vanilla TypeScript. No font downloads, JavaScript frameworks or polyfills for evergreen browsers. 🐦🌲\n   All these above lines are stolen from Utterances home page!\n Setting up Utterances is quite simple, just follow the home page instruction and you will get what you want.\nSo, let\u0026rsquo;s post some comments here.\n"},{"id":22,"href":"/blog/gallery/","title":"Gallery","section":"About","content":"Stores my photos and pictures that I love!\n"},{"id":23,"href":"/blog/posts/","title":"Posts","section":"About","content":"Welcome to the blog section!\n"},{"id":24,"href":"/blog/authors/kiennt/","title":"Index","section":"Authors","content":"Brief #       Engineer Follow @ntk148v Basketball junkie 🏀 Love taking lifestyle photos 📷 \u0026amp; drawing ✏️ OpenSource contributor \u0026amp; lover  Getting in touch #  Email is probably best, get me directly on kiennt2609@gmail.com or reach me out on my online profiles 👇\n                       "}]