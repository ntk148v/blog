<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>faythe on /home/kiennt</title>
    <link>/blog/tags/faythe/</link>
    <description>Recent content in faythe on /home/kiennt</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Aug 2019 21:19:38 +0700</lastBuildDate>
    
        <atom:link href="/blog/tags/faythe/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Openstack Autoscaling New Approach</title>
      <link>/blog/posts/openstack-autoscaling-new-approach/</link>
      <pubDate>Mon, 19 Aug 2019 21:19:38 +0700</pubDate>
      
      <guid>/blog/posts/openstack-autoscaling-new-approach/</guid>
      <description>NOTE(kiennt): There is a legacy Faythe guideline. The new version is coming soon, check its repository for status.
 This guide describes how to automatically scale out your Compute instances in response to heavy system usage. By combining with Prometheus pre-defined rules that consider factors such as CPU or memory usage, you can configure OpenStack Orchestration (Heat) to add and remove additional instances automatically, when they are needed.
1. The standard OpenStack Autoscaling approach Let&amp;rsquo;s talk about the standard OpenStack Autoscaling approach before goes to the new approach.</description>
      
    </item>
    
  </channel>
</rss>
